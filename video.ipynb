{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from retinanet.retinanet.model import RetinaNet\n",
    "from retinanet.utils.image import normalize_image, denormalize_image\n",
    "from retinanet.utils.eval import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = 'resnet50'\n",
    "inference_model_path = 'inferences/resnet50_sinsinsa_270.h5'\n",
    "pyramids = ['P3', 'P4', 'P5', 'P6', 'P7']\n",
    "use_p2 = False\n",
    "\n",
    "SINSINSA_CLASSES = {\n",
    "    0: 'screw',\n",
    "    1: 'hole'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model inferences/resnet50_sinsinsa_270.h5\n",
      "finish loading model\n"
     ]
    }
   ],
   "source": [
    "retinanet = RetinaNet(backbone)\n",
    "model = retinanet.load_model(inference_model_path,\n",
    "                                       p2=use_p2,\n",
    "                                       convert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video demo.mp4\n",
      "[MoviePy] Writing video demo.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244/244 [00:57<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: demo.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def label_to_name(label):\n",
    "    return SINSINSA_CLASSES[label]\n",
    "\n",
    "\n",
    "def predict_detections(model, image, score_threshold: float = 0.05, max_detections: int = 300, ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param image: (height, width, 3) a single image\n",
    "    :param scale: rescaling floating point value\n",
    "    :param score_threshold: all predicted boxes less than score threshold will be dropped\n",
    "    :param max_detections: the maximum number of detections to limit\n",
    "    :return:  boxes with score and label. ((x1, y1, x2, y2, label, score), ...)\n",
    "    \"\"\"\n",
    "\n",
    "    # Predict with the inference model\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "    # Select indices which are over the threshold score\n",
    "    indices = np.where(scores[0, :] > score_threshold)[0]\n",
    "\n",
    "    # select those scores\n",
    "    scores = scores[0][indices]\n",
    "\n",
    "    # Sort scores in descending order. shape : (300, )\n",
    "    sorted_scores = np.argsort(-scores)[:max_detections]\n",
    "\n",
    "    # select detections\n",
    "    image_boxes = boxes[0, indices[sorted_scores], :]\n",
    "    image_scores = scores[sorted_scores]\n",
    "    image_labels = labels[0, indices[sorted_scores]]  # (300, )\n",
    "\n",
    "    image_detections = np.concatenate(\n",
    "        [image_boxes, np.expand_dims(image_labels, axis=1), np.expand_dims(image_scores, axis=1)], axis=1)\n",
    "\n",
    "    return image_detections\n",
    "\n",
    "def transform(image):\n",
    "    image = normalize_image(image)\n",
    "    image_for_prediction = image.copy()\n",
    "    image_for_prediction[540:900] = 0\n",
    "    detections = predict_detections(model, image_for_prediction)\n",
    "    image = denormalize_image(image)\n",
    "    \n",
    "    Evaluator.draw_detections(image, detections, detections[:, 4], detections[:, 5],\n",
    "                                 thickness=6, label_to_name=label_to_name)\n",
    "\n",
    "    image = image.astype(np.int)\n",
    "    return image\n",
    "clip = VideoFileClip('cut.mov')\n",
    "clip = clip.fl_image(transform)\n",
    "clip.write_videofile('demo.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
